{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c754af2",
   "metadata": {},
   "source": [
    "# Adding Memory to a Chain (Part 2): Creating the Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e017933e-9d23-4a6c-8655-99b9ed298608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the line of code below to check the version of langchain in the current environment.\n",
    "# Substitute \"langchain\" with any other package name to check their version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97b1d7-57d7-4f88-9828-8b2dd4130a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cd3721",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8106a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = '''\n",
    "The following is a friendly conversation between a human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "{message_log}\n",
    "\n",
    "Human: \n",
    "{question}\n",
    "\n",
    "AI:\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246653f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name = 'gpt-4', \n",
    "                  model_kwargs = {'seed':365},\n",
    "                  temperature = 0,\n",
    "                  max_tokens = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19393041",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_memory = ConversationSummaryMemory(llm = ChatOpenAI(),\n",
    "                                        memory_key=\"message_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a65003",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Can you give me an interesting fact I probably didn't know about?\"\n",
    "# question = \"Can you elaborate a bit more on this fact?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc9123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_output = RunnablePassthrough.assign(\n",
    "    message_log = RunnableLambda(chat_memory.load_memory_variables) | \n",
    "    itemgetter('message_log')).invoke(\n",
    "    {'question':question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf243fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_value_output = prompt_template.invoke(dictionary_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cd5cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message_output = chat.invoke(prompt_value_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520a770",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = StrOutputParser().invoke(ai_message_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73759f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_memory.save_context(inputs = {'input':question}, \n",
    "                         outputs = {'output':response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c05450",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a714a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = (\n",
    "    RunnablePassthrough.assign(\n",
    "        message_log = RunnableLambda(chat_memory.load_memory_variables) | \n",
    "        itemgetter('message_log')) \n",
    "    | prompt_template \n",
    "    | chat \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"Can you elaborate a bit more on this fact?\"\n",
    "\n",
    "response = chain1.invoke({'question':question})\n",
    "\n",
    "chat_memory.save_context(inputs = {'input':question}, \n",
    "                         outputs = {'output':response})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8fadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def memory_chain(question):\n",
    "    \n",
    "    chain1 = (\n",
    "        RunnablePassthrough.assign(\n",
    "            message_log = RunnableLambda(chat_memory.load_memory_variables) | \n",
    "            itemgetter('message_log')) \n",
    "        | prompt_template \n",
    "        | chat \n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    chain1.get_graph().print_ascii()\n",
    "\n",
    "    response = chain1.invoke({'question':question})\n",
    "\n",
    "    chat_memory.save_context(inputs = {'input':question}, \n",
    "                             outputs = {'output':response})\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d39cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "memory_chain.invoke(\"Can you elaborate a bit more on this fact?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114b0372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f631960a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
