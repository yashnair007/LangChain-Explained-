{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67f3d7b4-cdad-4fcd-b9e5-293e22107804",
   "metadata": {},
   "source": [
    "# Creating a Sarcastic Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54383858",
   "metadata": {},
   "source": [
    "Welcome back, everyone!\n",
    "\n",
    "In this lesson, we’ll resume the implementation of our chat completion in Jupyter Notebook. We’ll start by instructing the chatbot to answer questions sarcastically through a system message and then pass our question as a user-role message. \n",
    "\n",
    "Let’s get into it!\n",
    "\n",
    "For starters, run the first four code cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb9401-edaf-49a9-8bde-958f8ea58b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1260d8b-720e-4ab2-8401-48f7ae60f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29101bb-60f9-4d90-b6ec-ff3433d2eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e07b869-3991-4fdd-b702-a0681023d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b338c4",
   "metadata": {},
   "source": [
    "Now, the first dictionary in our **messages** list should map the ‘role’ keyword to ‘system’, implying a system message. \n",
    "In addition, set the content to the one already familiar to you:\n",
    "*You are Marv, a chatbot that reluctantly answers questions with sarcastic responses.*\n",
    "\n",
    "In the second dictionary in the list, we’ll create a user message. I’ll go with the following request:\n",
    "*I’ve recently adopted a dog. Could you suggest some dog names?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8cc4c3-0097-432d-8b81-0570a353a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(model = 'gpt-4', \n",
    "                                            messages = [{'role':'system', \n",
    "                                                         'content':''' You are Marv, a chatbot that reluctantly \n",
    "                                                         answers questions with sarcastic responses. '''}, \n",
    "                                                        {'role':'user', \n",
    "                                                         'content':''' I've recently adopted a dog. \n",
    "                                                         Could you suggest some dog names? '''}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63866528",
   "metadata": {},
   "source": [
    "Run the cell above and inspect the **completion** variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917b4323-3319-4daf-bd2e-b7e5e423f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3fc795-1d2e-45ef-90d0-bb645f85399b",
   "metadata": {},
   "source": [
    "We find that **completion** is an instance of the **ChatCompletion** class, with the parameter **choices** storing a list of **Choice** objects that, in turn, keep the responses from the chatbot. By default, the model returns only one response, which is typically the desired setting. This number can be controlled through a parameter called **n**. Of course, more responses result in higher token consumption and, therefore, higher cost.\n",
    "\n",
    "The role assigned to this message is ‘assistant.’ Additionally, information is available on the number of completion, prompt, and total tokens. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1271f864",
   "metadata": {},
   "source": [
    "Finally, for this lesson, let’s check how the chatbot responded by displaying the output in a more readable form. \n",
    "To do that: \n",
    "<ul>\n",
    "  <li>first, retrieve the <strong>choices</strong> list from the <strong>ChatCompletion</strong> object, </li>\n",
    "  <li>then select the first and only item in this list, </li>\n",
    "  <li>fetch the <strong>messages</strong> parameter from the <strong>Choice</strong> object,</li>\n",
    "  <li>and lastly, extract the content from the <strong>ChatCompletionMessage</strong> object.</li>\n",
    "</ul>\n",
    "Make sure you apply the <strong>print</strong>-function to the string to ensure the message is nicely formatted. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad1b74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d7f8db",
   "metadata": {},
   "source": [
    "Excellent job, everyone. \n",
    "\n",
    "In the upcoming lesson, we’ll discuss additional parameters that can help further control the model’s response.\n",
    "\n",
    "See you in a bit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73809d58-5915-4499-9c38-5b21ed0d6a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2820df6-6ef1-4cd8-87a7-deeacdaf52f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
