{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67f3d7b4-cdad-4fcd-b9e5-293e22107804",
   "metadata": {},
   "source": [
    "# First Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679c1b82-cfc0-45bd-a07f-a9e476cf2cd1",
   "metadata": {},
   "source": [
    "Welcome back to the course everyone!\n",
    "In the previous section, we used the Anaconda Prompt to create a new environment called **langchain_env**. \n",
    "As emphasized, itâ€™s recommended that individual projects be run in separate environments to prevent package conflicts or the accidental removal of important documents. They also offer the flexibility to install different Python versions and maintain unique package sets in each without the risk of interfering with the base setup. \n",
    "\n",
    "We also registered this environment as a Jupyter kernel so that we could use it in our Jupyter notebooks. Finally, we set our OpenAI API key as an environment variable, allowing us to utilize OpenAIâ€™s models and API.\n",
    "\n",
    "Iâ€™m now happy to welcome you to this lesson, where weâ€™ll create our first chatbot. Weâ€™ll be relying on Python and OpenAIâ€™s API. Note that we wonâ€™t be making use of the LangChain framework just yet. This section introduces you to creating chatbots with OpenAIâ€™s API and familiarizes you with its main components. Since OpenAIâ€™s integration in LangChain relies heavily on this API, having a general idea of how it works is valuable. \n",
    "\n",
    "With that said, letâ€™s get to coding! ðŸ˜Š\n",
    "\n",
    "Load the **dotenv**  extension and then apply the **%dotenv** magic command to set your OpenAI API key as an environment variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb9401-edaf-49a9-8bde-958f8ea58b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50863e77",
   "metadata": {},
   "source": [
    "Next, we should configure the OpenAI library to recognize our key. To do so, import the **os** and **openai** libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1260d8b-720e-4ab2-8401-48f7ae60f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70bf8b0",
   "metadata": {},
   "source": [
    "Then, set **openai.api_key** to equal **os.getenv('OPENAI_API_KEY')**, passing the name of the environment variable as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29101bb-60f9-4d90-b6ec-ff3433d2eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c973216",
   "metadata": {},
   "source": [
    "Weâ€™re now ready to experiment with OpenAIâ€™s models. Weâ€™ll do so by implementing a helpful chatbot that answers usersâ€™ questions. \n",
    "But weâ€™ll also give it a sarcastic twist. ðŸ˜Š\n",
    "\n",
    "First, create an OpenAI client by utilizing OpenAIâ€™s class of the same name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e07b869-3991-4fdd-b702-a0681023d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de81601",
   "metadata": {},
   "source": [
    "Then, define a **completion** variable that will serve as our chatbot object. Set it equal to **client.chat.completions.create**. \n",
    "\n",
    "The first parameter that the **create()** function requires is the model. Iâ€™ll opt for GPT-4, but you can experiment with any OpenAI chat model. Just visit their website, pick a language model of your choice, and write the respective name as a string. \n",
    "Keep in mind our discussion about costsâ€”especially if you plan on working on your own projects. Make sure you opt for a cost-sensitive variant.\n",
    "\n",
    "The second required parameter (**messages**) contains the messages weâ€™ll give the model before starting the conversation. These messages will be a way to instruct the model on how to behave. It expects a list of dictionaries, each containing two required key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8cc4c3-0097-432d-8b81-0570a353a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(model = 'gpt-4', \n",
    "                                            messages = [{}, \n",
    "                                                        {}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde7919",
   "metadata": {},
   "source": [
    "The key to the first pair is â€˜role,â€™ which can be mapped to one of the following values: â€˜system,â€™ â€˜user,â€™ â€˜assistant,â€™ and â€˜tool.â€™ Weâ€™ll work with tools later in the course. For now, letâ€™s focus on the first three. \n",
    "\n",
    "The key to the second pair is â€˜content,â€™ which stores strings with questions, instructions, or other helpful content that will guide the model towards responding suitably.\n",
    "\n",
    "All right! Next, weâ€™ll discuss the difference between system, user, and assistant roles. \n",
    "\n",
    "Catch you in a bit! ðŸ˜Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd6dd0-96eb-4f93-a1c3-384451725220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73809d58-5915-4499-9c38-5b21ed0d6a32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
